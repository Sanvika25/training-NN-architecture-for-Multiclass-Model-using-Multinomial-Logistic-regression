{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanvika25/training-NN-architecture-for-Multiclass-Model-using-Multinomial-Logistic-regression/blob/main/ann_week8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_uF-eDX_jBk"
      },
      "outputs": [],
      "source": [
        "# Load Data from sklearn package\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/Iris.csv')\n",
        "\n",
        "X = df.iloc[:,:5].values\n",
        "y = df.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare Feature Standardization\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers\n",
        "import tensorflow as tf\n",
        "#One hot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(sparse_output = False,categories = 'auto')\n",
        "y_encoded = enc.fit_transform(y.reshape(-1,1))\n",
        "\n",
        "# apply train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size = 0.2, random_state = 1)\n",
        "\n",
        "#y_enc = enc.transform(np.array(y_test).reshape(-1,1)) # Need to one-hot encode output for the neuralnetwork output layer\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(X_train)"
      ],
      "metadata": {
        "id": "uACneQtvAY-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_loss = []\n",
        "Test_accuracy = []\n",
        "Train_loss = []\n",
        "Train_accuracy = []\n"
      ],
      "metadata": {
        "id": "dgphSphDAlOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Neural Network\n",
        "\n",
        "#with no hidden layer\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = \"adam\",\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size = 2,validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ2uYuQRAupp",
        "outputId": "33e67a0a-5c5c-4e33-ad37-9d15fc0d348a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29 (120.00 Byte)\n",
            "Trainable params: 18 (72.00 Byte)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60/60 [==============================] - 1s 8ms/step - loss: 0.8455 - accuracy: 0.6583 - val_loss: 0.9782 - val_accuracy: 0.4667\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7922 - accuracy: 0.6833 - val_loss: 0.9225 - val_accuracy: 0.5333\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7444 - accuracy: 0.7250 - val_loss: 0.8733 - val_accuracy: 0.5333\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.7250 - val_loss: 0.8289 - val_accuracy: 0.5333\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.7250 - val_loss: 0.7873 - val_accuracy: 0.5333\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.7250 - val_loss: 0.7474 - val_accuracy: 0.5333\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.7250 - val_loss: 0.7154 - val_accuracy: 0.5667\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7250 - val_loss: 0.6823 - val_accuracy: 0.5667\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7333 - val_loss: 0.6545 - val_accuracy: 0.5667\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7583 - val_loss: 0.6263 - val_accuracy: 0.5667\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.6263 - accuracy: 0.5667\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Neural Network\n",
        "\n",
        "#with 1 hidden layers\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(8, activation = \"relu\", input_dim= 5))\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = \"adam\",\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size = 2,validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccuPLVHkA46R",
        "outputId": "557bcf60-bc37-4cd1-fb21-560bae2d51ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 48        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 86 (348.00 Byte)\n",
            "Trainable params: 75 (300.00 Byte)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60/60 [==============================] - 1s 5ms/step - loss: 1.3633 - accuracy: 0.4750 - val_loss: 1.0285 - val_accuracy: 0.6333\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0721 - accuracy: 0.4333 - val_loss: 0.8635 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.8466 - accuracy: 0.5083 - val_loss: 0.7426 - val_accuracy: 0.7000\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.7083 - val_loss: 0.6607 - val_accuracy: 0.6667\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.7000 - val_loss: 0.6047 - val_accuracy: 0.7000\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7167 - val_loss: 0.5575 - val_accuracy: 0.7333\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7417 - val_loss: 0.5223 - val_accuracy: 0.7667\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8083 - val_loss: 0.4902 - val_accuracy: 0.7667\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8333 - val_loss: 0.4642 - val_accuracy: 0.7667\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8333 - val_loss: 0.4385 - val_accuracy: 0.7667\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.4385 - accuracy: 0.7667\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with 2 hidden layers\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(8, activation = \"relu\", input_dim= 5))\n",
        "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = \"adam\",\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size = 2,validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVYQQgE0B-IL",
        "outputId": "05fb7ac0-c2ca-4373-b6ef-f7a2cac02131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 48        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 158 (636.00 Byte)\n",
            "Trainable params: 147 (588.00 Byte)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60/60 [==============================] - 1s 6ms/step - loss: 1.0762 - accuracy: 0.4000 - val_loss: 1.0590 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0297 - accuracy: 0.5500 - val_loss: 0.9822 - val_accuracy: 0.7333\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.9136 - accuracy: 0.8250 - val_loss: 0.8254 - val_accuracy: 0.7333\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7492 - accuracy: 0.8250 - val_loss: 0.6838 - val_accuracy: 0.7333\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.8250 - val_loss: 0.5785 - val_accuracy: 0.7667\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.8417 - val_loss: 0.5135 - val_accuracy: 0.7333\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8583 - val_loss: 0.4561 - val_accuracy: 0.7667\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8833 - val_loss: 0.4039 - val_accuracy: 0.7667\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.9250 - val_loss: 0.3504 - val_accuracy: 0.8667\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.9417 - val_loss: 0.3186 - val_accuracy: 0.9000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3186 - accuracy: 0.9000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2305 - accuracy: 0.9417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Neural Network\n",
        "\n",
        "#with 3 hidden layers\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(8, activation = \"relu\", input_dim= 5))\n",
        "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = \"adam\",\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size = 2,validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxymxJE8CBI7",
        "outputId": "4dfff4e2-eff1-470e-bfe6-34cb136d4c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 48        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 230 (924.00 Byte)\n",
            "Trainable params: 219 (876.00 Byte)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60/60 [==============================] - 1s 5ms/step - loss: 1.0969 - accuracy: 0.3750 - val_loss: 1.0954 - val_accuracy: 0.2000\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0770 - accuracy: 0.3667 - val_loss: 1.0709 - val_accuracy: 0.2000\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0141 - accuracy: 0.3667 - val_loss: 1.0101 - val_accuracy: 0.2000\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.9140 - accuracy: 0.5333 - val_loss: 0.9433 - val_accuracy: 0.5667\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.8321 - accuracy: 0.6833 - val_loss: 0.8991 - val_accuracy: 0.5667\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7779 - accuracy: 0.6917 - val_loss: 0.8630 - val_accuracy: 0.5667\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7290 - accuracy: 0.7083 - val_loss: 0.8173 - val_accuracy: 0.6000\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.8000 - val_loss: 0.7596 - val_accuracy: 0.7000\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.8333 - val_loss: 0.7197 - val_accuracy: 0.7667\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.8833 - val_loss: 0.6742 - val_accuracy: 0.7667\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.6742 - accuracy: 0.7667\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Neural Network\n",
        "\n",
        "#with 4 hidden layers\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(8, activation = \"relu\", input_dim= 5))\n",
        "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = \"adam\",\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size = 2,validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MALObimL4ixw",
        "outputId": "cbc92631-30a5-4536-bf01-2153894c4022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 8)                 48        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 302 (1.18 KB)\n",
            "Trainable params: 291 (1.14 KB)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60/60 [==============================] - 1s 7ms/step - loss: 1.0972 - accuracy: 0.3500 - val_loss: 1.0943 - val_accuracy: 0.2000\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 1.0731 - accuracy: 0.2917 - val_loss: 1.0435 - val_accuracy: 0.1667\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.9601 - accuracy: 0.3667 - val_loss: 0.9202 - val_accuracy: 0.5667\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.8311 - accuracy: 0.6750 - val_loss: 0.8828 - val_accuracy: 0.5667\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7687 - accuracy: 0.6917 - val_loss: 0.8699 - val_accuracy: 0.5667\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.6917 - val_loss: 0.8356 - val_accuracy: 0.5667\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.6917 - val_loss: 0.8241 - val_accuracy: 0.5667\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.7000 - val_loss: 0.8004 - val_accuracy: 0.5667\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.7167 - val_loss: 0.7665 - val_accuracy: 0.5667\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.7417 - val_loss: 0.7387 - val_accuracy: 0.5667\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.7387 - accuracy: 0.5667\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test loss, test acc, train loss, train acc\n",
        "print('  |TestL |TestA |TrainL| TrainA')\n",
        "print(\"===============================\")\n",
        "max_test_accuracy = 0\n",
        "min_test_loss = 1\n",
        "min_Train_loss = 1\n",
        "max_Train_accuracy = 0\n",
        "\n",
        "for i in range(5):\n",
        "  #print(f\"{Test_loss[i]}|{Test_accuracy[i]}|{Train_loss[i]}|{Train_accuracy[i]}\")\n",
        "  if (Test_loss[i]< min_test_loss):\n",
        "    min_test_loss = Test_loss[i]\n",
        "    min_test_loss_index = i\n",
        "\n",
        "  if (Test_accuracy[i] > max_test_accuracy):\n",
        "    max_test_accuracy = Test_accuracy[i]\n",
        "    max_test_accuracy_index = i\n",
        "\n",
        "  if (Train_loss[i]< min_Train_loss):\n",
        "    min_Train_loss = Train_loss[i]\n",
        "    min_Train_loss_index = i\n",
        "\n",
        "  if (Train_accuracy[i] > max_Train_accuracy):\n",
        "    max_Train_accuracy = Train_accuracy[i]\n",
        "    max_Train_accuracy_index = i\n",
        "\n",
        "  print(i, \"| %.2f |\" % Test_loss[i], \"%.2f |\" % Test_accuracy[i], \"%.2f |\" % Train_loss[i], \"%.2f |\" % Train_accuracy[i] )\n",
        "\n",
        "print()\n",
        "print(max_test_accuracy,\":\",max_test_accuracy_index)\n",
        "print(min_test_loss,\":\",min_test_loss_index)\n",
        "print(min_Train_loss,\":\",min_Train_loss_index)\n",
        "print(max_Train_accuracy,\":\",max_Train_accuracy_index)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"----ANALYSIS----\")\n",
        "print(max(Test_loss))\n",
        "print(max(Test_accuracy))\n",
        "print(max(Train_loss))\n",
        "print(max(Train_accuracy))\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(min(Test_loss))\n",
        "print(min(Test_accuracy))\n",
        "print(min(Train_loss))\n",
        "print(min(Train_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN9YIKD04k6V",
        "outputId": "7063de61-8e0b-4924-8261-c0915eb4e816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  |TestL |TestA |TrainL| TrainA\n",
            "===============================\n",
            "0 | 0.63 | 0.57 | 0.50 | 0.76 |\n",
            "1 | 0.44 | 0.77 | 0.36 | 0.84 |\n",
            "2 | 0.32 | 0.90 | 0.23 | 0.94 |\n",
            "3 | 0.67 | 0.77 | 0.56 | 0.90 |\n",
            "4 | 0.74 | 0.57 | 0.61 | 0.76 |\n",
            "\n",
            "0.8999999761581421 : 2\n",
            "0.31855878233909607 : 2\n",
            "0.23048824071884155 : 2\n",
            "0.9416666626930237 : 2\n",
            "\n",
            "\n",
            "----ANALYSIS----\n",
            "0.7387320399284363\n",
            "0.8999999761581421\n",
            "0.6121492981910706\n",
            "0.9416666626930237\n",
            "\n",
            "\n",
            "0.31855878233909607\n",
            "0.5666666626930237\n",
            "0.23048824071884155\n",
            "0.7583333253860474\n"
          ]
        }
      ]
    }
  ]
}